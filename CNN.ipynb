{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["RlemX_aQ0D5Q"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vNt7fSoZWlyQ","colab_type":"code","outputId":"4cd77838-e651-4140-fb30-f63c87f19d88","executionInfo":{"status":"ok","timestamp":1543282756900,"user_tz":0,"elapsed":2400,"user":{"displayName":"Nagy Helal","photoUrl":"https://lh6.googleusercontent.com/-ZqIF23b_kAw/AAAAAAAAAAI/AAAAAAAAADA/2pVRnGbx_qU/s64/photo.jpg","userId":"03796738283948297091"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import numpy as np \n","import pickle\n","from matplotlib import pyplot as plt\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.np_utils import to_categorical\n","from keras import models, layers\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"Y9I0F6PJNBCs","colab_type":"text"},"cell_type":"markdown","source":["## 1. Data loading & preprocessing"]},{"metadata":{"id":"WQX_NWufQUio","colab_type":"text"},"cell_type":"markdown","source":["### Set seed for reproducibility"]},{"metadata":{"id":"wj6dCMOKDFbA","colab_type":"code","colab":{}},"cell_type":"code","source":["SEED = 123\n","np.random.seed(SEED)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cw6tQyE3Qc9s","colab_type":"text"},"cell_type":"markdown","source":["### Load data"]},{"metadata":{"id":"I_Iz0td90lMQ","colab_type":"code","colab":{}},"cell_type":"code","source":["DIR = \"drive/My Drive/Colab Notebooks/input/\" # Location of input data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"056xpFX4XAfo","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = np.load(os.path.join(DIR, \"train_images.npy\"), encoding='latin1')\n","train_labels = np.genfromtxt(os.path.join(DIR, \"train_labels.csv\"), names=True, delimiter=',', dtype=[('Id', 'i8'), ('Category', 'S15')])\n","X_test = np.load(os.path.join(DIR, \"test_images.npy\"), encoding = 'latin1')\n","\n","X_train = np.array(tuple(x[1] for x in X_train))\n","X_test = np.array(tuple(x[1] for x in X_test))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xJpTJ4AqXM0s","colab_type":"text"},"cell_type":"markdown","source":["### One-hot encode image labels"]},{"metadata":{"id":"fnNWfdDAXN0w","colab_type":"code","colab":{}},"cell_type":"code","source":["# Numerical encoding\n","y_train = train_labels[:]['Category']\n","y_train = preprocessing.LabelEncoder().fit_transform(y_train)\n","\n","# One-hot encoding for keras\n","n_classes = len(np.unique(y_train))\n","y_train = to_categorical(y_train, n_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_jfpAOcWAxIY","colab_type":"text"},"cell_type":"markdown","source":["### Normalize data"]},{"metadata":{"id":"JK1-Zjx3AwIU","colab_type":"code","colab":{}},"cell_type":"code","source":["# converts images to greyscale\n","X_train = preprocessing.normalize(X_train)\n","X_test = preprocessing.normalize(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YNEEyLtrXYLQ","colab_type":"text"},"cell_type":"markdown","source":["### (SEE TODO): Standardize Data"]},{"metadata":{"id":"taY9tFb2XcTU","colab_type":"code","colab":{}},"cell_type":"code","source":["## TODO IS THIS REALLY NEEDED (ALL FEATURES ARE ON THE SAME SCALE)\n","scaler = preprocessing.StandardScaler()\n","scaler.fit(X_train)\n","\n","X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OUvmY7oHDTEc","colab_type":"text"},"cell_type":"markdown","source":["### Split into training and validation sets"]},{"metadata":{"id":"-E_MJHuKDVlY","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n","                                                      y_train,\n","                                                      random_state=SEED,\n","                                                      stratify=y_train/len(y_train)\n","                                                     )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NZ8IbbJIF4X4","colab_type":"code","colab":{}},"cell_type":"code","source":["# Reshape to 4D tensor (last dimension is nb. of channels)\n","# Required by keras models\n","X_train = X_train.reshape(X_train.shape[0], 100, 100, 1)\n","X_valid = X_valid.reshape(X_valid.shape[0], 100, 100, 1)\n","X_test = X_test.reshape(X_test.shape[0], 100, 100, 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hoyrXviWXChU","colab_type":"text"},"cell_type":"markdown","source":["### Augment data through transformations"]},{"metadata":{"id":"dbyRs1olgKO8","colab_type":"code","colab":{}},"cell_type":"code","source":["# Training batch size\n","# TODO PLAY AROUND WITH THIS\n","BATCH_SIZE = 128"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pxVYEpMkK_Lw","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load datagen if already saved\n","path_to_datagen = os.path.join(DIR, \"datagen\")\n","\n","try:\n","    with open(path_to_datagen, \"rb\") as f:\n","        path_to_datagen = pickle.load(f)\n","        \n","except FileNotFoundError:\n","    # Create datagen\n","    datagen = ImageDataGenerator(# zca_whitening=True, # EXTREMELY SLOW dimensionality reduction\n","                                rotation_range=30, # rotate images by [0,30] deg.\n","                                horizontal_flip=True,\n","                                )\n","# TODO SHOULD I SET FEATUREWISE_CENTER TO TRUE? IF YES, SHOULD I STILL NORMALIZE DATA BEFORE RUNNING THIS?    \n","    datagen.fit(X_train,\n","               seed=SEED\n","               )\n","\n","    # Save datagen to file\n","    path_to_datagen = os.path.join(DIR, \"datagen\")\n","    with open(path_to_datagen, \"wb\") as f:\n","        pickle.dump(datagen, f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tLhID8jIgPT8","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train_transformed = datagen.flow(X_train,\n","                y_train,\n","                batch_size=BATCH_SIZE,\n","                seed=SEED\n","               )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vJzd2-ddsWVs","colab_type":"text"},"cell_type":"markdown","source":["## 2. Model"]},{"metadata":{"id":"RlemX_aQ0D5Q","colab_type":"text"},"cell_type":"markdown","source":["### Convolution auto-encoder for noise reduction"]},{"metadata":{"id":"AUoFakMf9yvs","colab_type":"code","colab":{}},"cell_type":"code","source":["path_to_cae = os.path.join(DIR, \"cae.h5\")\n","if os.path.isfile(path_to_cae):\n","    cae = models.load_model(cae)\n","\n","else:\n","    \n","    input_img = layers.Input(shape=(100, 100, 1))\n","    \n","    encoded = layers.Conv2D(16,\n","                           (3,3),\n","                           padding=\"same\",\n","                           activation=\"relu\")(input_img)\n","    \n","    encoded = layers.MaxPooling2D((2, 2), padding='same')(encoded)\n","\n","    encoded = layers.Conv2D(8,\n","                           (3,3),\n","                           padding=\"same\",\n","                           activation=\"relu\")(encoded)\n","\n","    encoded = layers.MaxPooling2D((2, 2), padding='same')(encoded)\n","\n","    encoded = layers.Conv2D(8,\n","                           (3,3),\n","                           padding=\"same\",\n","                           activation=\"relu\")(encoded)\n","\n","    encoded = layers.MaxPooling2D((2, 2), padding='same')(encoded)\n","    \n","    decoded = layers.Conv2D(8,\n","                            (3, 3),\n","                            activation='relu',\n","                            padding='same')(encoded)\n","\n","    decoded = layers.UpSampling2D((2, 2))(decoded)\n","\n","    decoded = layers.Conv2D(8,\n","                            (3, 3),\n","                            activation='relu',\n","                            padding='same')(encoded)\n","\n","    decoded = layers.UpSampling2D((2, 2))(decoded)\n","    \n","    decoded = layers.Conv2D(16,\n","                            (3, 3),\n","                            activation='relu',\n","                            padding='same')(encoded)\n","\n","    decoded = layers.UpSampling2D((2, 2))(decoded)\n","\n","    decoded = layers.Conv2D(1,\n","                            (3, 3),\n","                            activation='sigmoid',\n","                            padding='same')(decoded)\n","\n","    cae = models.Model(input_img, decoded)\n","    cae.compile(optimizer='adadelta',\n","                        loss='binary_crossentropy')\n","\n","    cae.fit(X_train,\n","            X_train, # X_train is intentionally passed twice. The autoencoder requires that\n","            epochs = 50,\n","            batch_size = BATCH_SIZE,\n","            validation_data = (X_valid, X_valid),\n","           )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mi3NnbG2DTYg","colab_type":"code","colab":{}},"cell_type":"code","source":["cae.save(path_to_cae)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xl2y_o6V2jJc","colab_type":"text"},"cell_type":"markdown","source":["### CNN"]},{"metadata":{"id":"G0E_T-Aa2iSw","colab_type":"code","colab":{}},"cell_type":"code","source":["path_to_cnn = os.path.join(DIR, \"cnn.h5\")\n","if os.path.isfile(path_to_cnn):\n","        cnn = models.load_model(path_to_cnn)\n","\n","else:\n","    \n","    # Create CNN\n","\n","    cnn = models.Sequential()\n","\n","    cnn.add(layers.Conv2D(filters=32, # TODO PLAY AROUND WITH THIS\n","                         kernel_size=(5, 5), # TODO PLAY AROUND WITH THIS\n","                         activation=\"relu\",\n","                         input_shape=(100, 100, 1), # TODO PLAY AROUND WITH THIS\n","                         padding=\"same\",\n","                         ))\n","\n","    cnn.add(layers.Conv2D(filters=64, # TODO PLAY AROUND WITH THIS\n","                         kernel_size=(5, 5), # TODO PLAY AROUND WITH THIS\n","                         activation=\"relu\",\n","                         padding=\"same\",\n","                         ))\n","\n","    cnn.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","    \n","    cnn.add(layers.Dropout(0.25))\n","\n","    cnn.add(layers.Conv2D(filters=32, # TODO PLAY AROUND WITH THIS\n","                         kernel_size=(3, 3), # TODO PLAY AROUND WITH THIS\n","                         activation=\"relu\",\n","                         padding=\"same\",\n","                         ))\n","\n","    cnn.add(layers.Conv2D(filters=64, # TODO PLAY AROUND WITH THIS\n","                         kernel_size=(3, 3), # TODO PLAY AROUND WITH THIS\n","                         activation=\"relu\",\n","                         padding=\"same\",\n","                         ))\n","    \n","    cnn.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","    cnn.add(layers.Dropout(0.25)) # Randomly drop 25% percent of features\n","    \n","    cnn.add(layers.Flatten())\n","\n","    cnn.add(layers.Dense(256, activation=\"relu\")) # TODO PLAY AROUND WITH THIS\n","\n","    cnn.add(layers.Dropout(0.5)) # Randomly drop 25% percent of features\n","\n","    cnn.add(layers.Dense(n_classes, activation=\"softmax\"))\n","\n","\n","    cnn.compile(optimizer=keras.optimizers.Adadelta(),\n","               loss=\"categorical_crossentropy\",\n","               metrics=[\"accuracy\"])\n","    # Fit CNN\n","    losses = cnn.fit_generator(X_train_transformed,\n","                     epochs=150,\n","                     steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n","                     verbose=2, \n","                     validation_data=(X_valid, y_valid),\n","                     )\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nSqxmi2F5BU4","colab_type":"code","colab":{}},"cell_type":"code","source":["cnn.save(os.path.join(DIR, \"CNN\"))"],"execution_count":0,"outputs":[]}]}